import pytest
import torch
from unittest.mock import AsyncMock, MagicMock
from src.backend.features import predict
import asyncio

"""
Test variables
"""
WINDOW_SIZE = 512
WINDOW_OVERLAP = 128
NUM_PREDS = 5
TASK_ID = "05a7a1f9-6071-4467-9af2-52165657a685"

text = "Ἐν ἀρχῇ ἦν ὁ [MASK], καὶ ὁ λόγος ἦν πρὸς τὸν θεόν, καὶ θεὸς ἦν ὁ λόγος."

text_token_ids = [
        2,
        477,
        1774,
        629,
        95,
        4,
        12,
        453,
        95,
        1040,
        629,
        547,
        510,
        1154,
        12,
        453,
        921,
        629,
        95,
        1040,
        14,
        3,
    ]

# mock progress_callback and cancellation_event
mock_progress_callback = AsyncMock()
cancellation_event = asyncio.Event()


"""
Unit test for prediction_function
"""


@pytest.fixture(scope="module")
def mock_model_and_tokenizer():
    """
    Create mock model and tokenizer
    Uses token_ids and attention_mask generated by LOGION-50k_wordpiece
    """
    mock_tokenizer = MagicMock()
    mock_tokenizer.encode.return_value = text_token_ids
    mock_tokenizer.decode.side_effect = (
        lambda ids: (text)
    )
    mock_tokenizer.mask_token_id = 4  # [MASK] ID == 4
    mock_tokenizer.convert_ids_to_tokens.side_effect = lambda ids: [
        "[MASK]" if i == 4 else f"token_{i}" for i in ids
    ]

    def mock_tokenizer_call(
        text,
        return_tensors,
        return_attention_mask,
        add_special_tokens,
        truncation,
        max_length,
    ):
        return {
            "input_ids": torch.tensor(
                [text_token_ids]
            ),
            "attention_mask": torch.tensor(
                [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
            ),
        }

    mock_tokenizer.side_effect = mock_tokenizer_call

    mock_model = MagicMock()
    logits = torch.rand(
        (1, len(text_token_ids), 50000)
    )  # mock logits (batch_size = 1, sequence_length = 22, vocab_size = 50k)
    mock_model.return_value.logits = logits

    device = torch.device("cpu")

    return mock_model, mock_tokenizer, device


@pytest.mark.asyncio
async def test_predict_data(mock_model_and_tokenizer):
    """
    Test input-output data behavior for prediction_function
    Uses mock tokenizer and model

    Asserts:
        1. Length of output matches number of [MASK]s
        2. Valid output data types
        3. Check progress_callback calls
            - called five times
            - correct messages with progress percentages
    """

    model, tokenizer, device = mock_model_and_tokenizer

    mask_count = text.count("[MASK]")

    final_predictions = await predict.prediction_function(
        text=text,
        model=model,
        tokenizer=tokenizer,
        device=device,
        window_size=WINDOW_SIZE,
        overlap=WINDOW_OVERLAP,
        num_predictions=NUM_PREDS,
        task_id=TASK_ID,
        progress_callback=mock_progress_callback,
        cancellation_event=cancellation_event
    )

    # check output data types
    assert isinstance(final_predictions, dict)
    assert len(final_predictions) == mask_count
    for mask_global_index, predictions_list in final_predictions.items():
        assert isinstance(mask_global_index, int)
        assert isinstance(predictions_list, list)
        assert len(predictions_list) == NUM_PREDS
        for predicted_token, probability_score in predictions_list:
            assert isinstance(predicted_token, str)
            assert isinstance(probability_score, float)

    # check progress_callback is called
    mock_progress_callback.assert_called()
    # check correct progress_callback messages called
    mock_progress_callback.assert_any_call(15.0, "Tokenizing text...")
    mock_progress_callback.assert_any_call(20.0, "Chunking text...")
    mock_progress_callback.assert_any_call(20.0, "Processing chunk 1/1...")
    mock_progress_callback.assert_any_call(95.0, "Gathering all predictions...")
    mock_progress_callback.assert_any_call(97.0, "Generated predictions.")
    # check progress_callback called 5 times (per text length)
    assert mock_progress_callback.call_count == 5