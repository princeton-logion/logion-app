import pytest
import torch
from unittest.mock import patch, MagicMock
from src.backend.features import predict


"""
Unit test for prediction_function
Uses mock tokenizer and model
"""


@pytest.fixture(scope="module")
def mock_model_and_tokenizer():
    """
    Create mock model and tokenizer
    Uses token_ids and attention_mask generated by LOGION-50k_wordpiece
    """
    mock_tokenizer = MagicMock()
    mock_tokenizer.encode.return_value = [
        2,
        477,
        1774,
        629,
        95,
        4,
        12,
        453,
        95,
        1040,
        629,
        547,
        510,
        1154,
        12,
        453,
        921,
        629,
        95,
        1040,
        14,
        3,
    ]
    mock_tokenizer.decode.side_effect = (
        lambda ids: (
            "Ἐν ἀρχῇ ἦν ὁ [MASK], καὶ ὁ λόγος ἦν πρὸς τὸν θεόν, καὶ θεὸς ἦν ὁ λόγος."
        )
    )
    mock_tokenizer.mask_token_id = 4  # [MASK] == 4
    mock_tokenizer.convert_ids_to_tokens.side_effect = lambda ids: [
        "[MASK]" if i == 4 else f"token_{i}" for i in ids
    ]

    def mock_tokenizer_call(
        text,
        return_tensors,
        return_attention_mask,
        add_special_tokens,
        truncation,
        max_length,
    ):
        return {
            "input_ids": torch.tensor(
                [
                    [
                        2,
                        477,
                        1774,
                        629,
                        95,
                        4,
                        12,
                        453,
                        95,
                        1040,
                        629,
                        547,
                        510,
                        1154,
                        12,
                        453,
                        921,
                        629,
                        95,
                        1040,
                        14,
                        3,
                    ]
                ]
            ),
            "attention_mask": torch.tensor(
                [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
            ),
        }

    mock_tokenizer.side_effect = mock_tokenizer_call  # mock tokenizer

    mock_model = MagicMock()
    logits = torch.rand(
        (1, 22, 50000)
    )  # mock logits (batch_size = 1, sequence_length = 22, vocab_size = 50k)
    mock_model.return_value.logits = logits

    device = torch.device("cpu")

    return mock_model, mock_tokenizer, device


def test_predict_data(mock_model_and_tokenizer):
    """
    Test input-output data behavior for prediction_function

    Asserts:
        1. Length of output matches number of [MASK]s
        2. Valid output data types
    """
    model, tokenizer, device = mock_model_and_tokenizer

    text = "Ἐν ἀρχῇ ἦν ὁ [MASK], καὶ ὁ λόγος ἦν πρὸς τὸν θεόν, καὶ θεὸς ἦν ὁ λόγος."

    mask_count = text.count("[MASK]")

    final_predictions = predict.prediction_function(text, model, tokenizer, device)

    # check output data types
    assert isinstance(final_predictions, dict)
    assert len(final_predictions) == mask_count
    for mask_index, predictions in final_predictions.items():
        assert isinstance(mask_index, int)
        assert isinstance(predictions, list)
        assert len(predictions) == 5
        for predicted_token, probability_score in predictions:
            assert isinstance(predicted_token, str)
            assert isinstance(probability_score, float)
